#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Router para ExportaÃ§Ã£o de VÃ­deo Final - TecnoCursos AI

Este mÃ³dulo implementa endpoints REST para exportaÃ§Ã£o completa de vÃ­deos
com integraÃ§Ã£o de TTS, avatar e montagem usando MoviePy.

Funcionalidades:
- GeraÃ§Ã£o de Ã¡udio TTS com Hugging Face Bark
- IntegraÃ§Ã£o com avatar Hunyuan3D-2 (simulaÃ§Ã£o no MVP)
- Montagem de vÃ­deo com MoviePy
- TransiÃ§Ãµes entre cenas
- Efeitos visuais e animaÃ§Ãµes
- Download do vÃ­deo final

Autor: TecnoCursos AI
Data: 17/01/2025
"""

from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks, UploadFile, File
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any, Union
import os
import time
import uuid
import asyncio
from datetime import datetime
from pathlib import Path
import json
import logging
from sqlalchemy.orm import Session
from app.database import get_db
from app.auth import get_current_user
from app.models import User, Project, Scene, Asset
from app.services.video_pipeline_service import export_project_video_with_ia
import smtplib
from email.mime.text import MIMEText

# Importar funÃ§Ãµes de geraÃ§Ã£o de vÃ­deo e TTS
try:
    from app.utils import (
        generate_narration,
        generate_avatar_video,
        create_video_from_text_and_audio
    )
    VIDEO_FUNCTIONS_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ FunÃ§Ãµes de vÃ­deo nÃ£o disponÃ­veis: {e}")
    VIDEO_FUNCTIONS_AVAILABLE = False

# Importar serviÃ§os TTS
try:
    from backend.services.tts_service import TTSConfig, TTSProvider
except ImportError:
    print("âš ï¸ ServiÃ§o TTS nÃ£o disponÃ­vel para video_export")
    # Definir TTSConfig localmente se nÃ£o estiver disponÃ­vel
    class TTSConfig:
        def __init__(self, **kwargs):
            pass
    TTSProvider = None

# Importar dependÃªncias do sistema
try:
    from app.auth import get_current_user
    from app.models import User
    from app.database import get_db
    AUTH_AVAILABLE = True
except ImportError:
    print("âš ï¸ Sistema de autenticaÃ§Ã£o nÃ£o disponÃ­vel")
    AUTH_AVAILABLE = False

# Importar MoviePy para montagem de vÃ­deo
try:
    from moviepy.editor import (
        VideoFileClip, AudioFileClip, ImageClip, CompositeVideoClip,
        concatenate_videoclips, ColorClip, TextClip, CompositeAudioClip
    )
    from moviepy.video.fx import resize, fadein, fadeout
    MOVIEPY_AVAILABLE = True
except ImportError:
    VideoFileClip = None
    AudioFileClip = None
    ImageClip = None
    ColorClip = None
    TextClip = None
    CompositeVideoClip = None
    concatenate_videoclips = None
    CompositeAudioClip = None
    import logging
    logging.warning('MoviePy nÃ£o disponÃ­vel - funcionalidades de vÃ­deo avanÃ§ado desativadas.')
    MOVIEPY_AVAILABLE = False

# Configurar router
router = APIRouter(
    prefix="/api/video-export",
    tags=["Video Export"],
    responses={
        404: {"description": "Video not found"},
        422: {"description": "Validation error"},
        500: {"description": "Internal server error"}
    }
)

# Configurar logger
logger = logging.getLogger(__name__)

# ===============================================================
# MODELOS PYDANTIC PARA REQUESTS/RESPONSES
# ===============================================================

class SceneElement(BaseModel):
    """Elemento de uma cena (texto, imagem, Ã¡udio)"""
    type: str = Field(..., description="Tipo do elemento: text, image, audio, avatar")
    content: str = Field(..., description="ConteÃºdo do elemento")
    duration: float = Field(default=3.0, description="DuraÃ§Ã£o em segundos")
    position: Dict[str, float] = Field(default={"x": 0.5, "y": 0.5}, description="PosiÃ§Ã£o na tela")
    size: Dict[str, float] = Field(default={"width": 0.8, "height": 0.6}, description="Tamanho relativo")
    animation: Optional[str] = Field(default=None, description="Tipo de animaÃ§Ã£o")
    style: Optional[Dict[str, Any]] = Field(default=None, description="Estilo visual")

class Scene(BaseModel):
    """ConfiguraÃ§Ã£o de uma cena"""
    id: str = Field(..., description="ID Ãºnico da cena")
    title: str = Field(..., description="TÃ­tulo da cena")
    duration: float = Field(default=5.0, description="DuraÃ§Ã£o total da cena")
    background: Optional[str] = Field(default=None, description="Imagem de fundo")
    elements: List[SceneElement] = Field(default=[], description="Elementos da cena")
    transition: Optional[str] = Field(default="fade", description="TransiÃ§Ã£o para prÃ³xima cena")
    tts_enabled: bool = Field(default=True, description="Se deve gerar TTS para texto")
    avatar_enabled: bool = Field(default=False, description="Se deve usar avatar")
    avatar_style: Optional[str] = Field(default="professional", description="Estilo do avatar")

class VideoExportRequest(BaseModel):
    """Request para exportaÃ§Ã£o de vÃ­deo"""
    title: str = Field(..., description="TÃ­tulo do vÃ­deo")
    description: Optional[str] = Field(default=None, description="DescriÃ§Ã£o do vÃ­deo")
    scenes: List[Scene] = Field(..., description="Lista de cenas")
    resolution: str = Field(default="1080p", description="ResoluÃ§Ã£o: 720p, 1080p, 4k")
    fps: int = Field(default=30, description="Frames por segundo")
    tts_voice: str = Field(default="pt_speaker_0", description="Voz para TTS")
    tts_provider: str = Field(default="auto", description="Provider TTS: auto, bark, gtts")
    background_music: Optional[str] = Field(default=None, description="MÃºsica de fundo")
    output_format: str = Field(default="mp4", description="Formato de saÃ­da")
    quality: str = Field(default="high", description="Qualidade: low, medium, high, ultra")

class VideoExportResponse(BaseModel):
    """Response da exportaÃ§Ã£o de vÃ­deo"""
    success: bool
    video_id: str
    message: str
    data: Dict[str, Any]

class VideoStatusResponse(BaseModel):
    """Status do processamento de vÃ­deo"""
    video_id: str
    status: str  # queued, processing, completed, failed
    progress: float
    current_stage: str
    estimated_time: Optional[int] = None
    error_message: Optional[str] = None
    video_url: Optional[str] = None
    file_size: Optional[int] = None
    duration: Optional[float] = None

# ===============================================================
# VARIÃVEIS GLOBAIS E CONFIGURAÃ‡Ã•ES
# ===============================================================

# Armazenamento temporÃ¡rio de jobs (em produÃ§Ã£o usar Redis)
video_jobs = {}

# ConfiguraÃ§Ãµes de resoluÃ§Ã£o
RESOLUTION_CONFIGS = {
    "720p": (1280, 720),
    "1080p": (1920, 1080),
    "4k": (3840, 2160)
}

# ConfiguraÃ§Ãµes de qualidade
QUALITY_CONFIGS = {
    "low": {"bitrate": "1000k", "crf": 28},
    "medium": {"bitrate": "2000k", "crf": 23},
    "high": {"bitrate": "4000k", "crf": 18},
    "ultra": {"bitrate": "8000k", "crf": 15}
}

# ===============================================================
# FUNÃ‡Ã•ES AUXILIARES
# ===============================================================

def create_text_clip(text: str, duration: float, resolution: tuple, style: Dict = None) -> Optional[Any]:
    """Cria clip de texto com MoviePy"""
    try:
        # ConfiguraÃ§Ãµes padrÃ£o
        default_style = {
            "fontsize": 48,
            "color": "white",
            "font": "Arial-Bold",
            "stroke_color": "black",
            "stroke_width": 2
        }

        if style:
            default_style.update(style)

        # Criar clip de texto
        txt_clip = TextClip(
            text,
            fontsize=default_style["fontsize"],
            color=default_style["color"],
            font=default_style["font"],
            stroke_color=default_style["stroke_color"],
            stroke_width=default_style["stroke_width"]
        )

        # Centralizar na tela
        txt_clip = txt_clip.set_position('center').set_duration(duration)

        return txt_clip

    except Exception as e:
        logger.error(f"Erro ao criar clip de texto: {e}")
        # Fallback: clip simples
        return TextClip(text, fontsize=36, color='white').set_position('center').set_duration(duration)

def create_image_clip(image_path: str, duration: float, resolution: tuple) -> Optional[Any]:
    if ImageClip is None:
        return None
    """Cria clip de imagem com MoviePy"""
    try:
        # Verificar se arquivo existe
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Imagem nÃ£o encontrada: {image_path}")

        # Criar clip de imagem
        img_clip = ImageClip(image_path)

        # Redimensionar para resoluÃ§Ã£o desejada
        img_clip = img_clip.resize(resolution)

        # Definir duraÃ§Ã£o
        img_clip = img_clip.set_duration(duration)

        return img_clip

    except Exception as e:
        logger.error(f"Erro ao criar clip de imagem: {e}")
        # Fallback: clip colorido
        return ColorClip(resolution, color=(100, 100, 100)).set_duration(duration)

def create_audio_clip(audio_path: str) -> AudioFileClip:
    """Cria clip de Ã¡udio com MoviePy"""
    try:
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"Ãudio nÃ£o encontrado: {audio_path}")

        return AudioFileClip(audio_path)

    except Exception as e:
        logger.error(f"Erro ao criar clip de Ã¡udio: {e}")
        return None

def add_transition(clip1, clip2, transition_type: str = "fade"):
    """Adiciona transiÃ§Ã£o entre clips"""
    try:
        if transition_type == "fade":
            # Fade out no primeiro clip
            clip1 = clip1.fadeout(0.5)
            # Fade in no segundo clip
            clip2 = clip2.fadein(0.5)
        elif transition_type == "slide":
            # Slide transition (implementaÃ§Ã£o bÃ¡sica)
            clip1 = clip1.fadeout(0.3)
            clip2 = clip2.fadein(0.3)
        elif transition_type == "zoom":
            # Zoom transition
            clip1 = clip1.fadeout(0.4)
            clip2 = clip2.fadein(0.4)

        return clip1, clip2

    except Exception as e:
        logger.error(f"Erro ao adicionar transiÃ§Ã£o: {e}")
        return clip1, clip2

async def generate_tts_for_scene(scene: Scene, tts_config: TTSConfig) -> Dict[str, str]:
    """Gera Ã¡udio TTS para elementos de texto da cena"""
    audio_files = {}

    if not TTSProvider:
        logger.warning("TTS nÃ£o disponÃ­vel, pulando geraÃ§Ã£o de Ã¡udio")
        return audio_files

    try:
        tts_service = TTSService()

        for element in scene.elements:
            if element.type == "text" and scene.tts_enabled:
                # Gerar Ã¡udio para texto
                text_content = element.content

                # Criar nome Ãºnico para arquivo
                audio_filename = f"tts_{scene.id}_{hash(text_content) % 100000}.mp3"
                audio_path = f"app/static/audios/{audio_filename}"

                # Garantir que diretÃ³rio existe
                os.makedirs(os.path.dirname(audio_path), exist_ok=True)

                # Gerar Ã¡udio
                result = await tts_service.generate_speech(text_content, tts_config, audio_path)

                if result.success:
                    audio_files[element.content] = audio_path
                    logger.info(f"âœ… Ãudio TTS gerado: {audio_path}")
                else:
                    logger.error(f"âŒ Erro ao gerar TTS: {result.error}")

        return audio_files

    except Exception as e:
        logger.error(f"Erro na geraÃ§Ã£o TTS: {e}")
        return audio_files

async def generate_avatar_for_scene(scene: Scene, audio_files: Dict[str, str]) -> Dict[str, str]:
    """Gera vÃ­deos de avatar para cenas que habilitaram avatar"""
    avatar_files = {}

    if not scene.avatar_enabled:
        return avatar_files

    try:
        for element in scene.elements:
            if element.type == "text" and element.content in audio_files:
                # Gerar avatar para este texto
                audio_path = audio_files[element.content]

                # Nome Ãºnico para vÃ­deo do avatar
                avatar_filename = f"avatar_{scene.id}_{hash(element.content) % 100000}.mp4"
                avatar_path = f"app/static/videos/avatars/{avatar_filename}"

                # Garantir que diretÃ³rio existe
                os.makedirs(os.path.dirname(avatar_path), exist_ok=True)

                # Gerar vÃ­deo do avatar
                result = generate_avatar_video(
                    text=element.content,
                    audio_path=audio_path,
                    output_path=avatar_path,
                    avatar_style=scene.avatar_style or "professional",
                    quality="high"
                )

                if result['success']:
                    avatar_files[element.content] = avatar_path
                    logger.info(f"âœ… Avatar gerado: {avatar_path}")
                else:
                    logger.error(f"âŒ Erro ao gerar avatar: {result['error']}")

        return avatar_files

    except Exception as e:
        logger.error(f"Erro na geraÃ§Ã£o de avatar: {e}")
        return avatar_files

def create_scene_clip(scene: Scene, audio_files: Dict[str, str], avatar_files: Dict[str, str],
                     resolution: tuple, fps: int) -> VideoFileClip:
    """Cria clip completo de uma cena"""
    try:
        clips = []
        audio_clips = []

        # Processar elementos da cena
        for element in scene.elements:
            if element.type == "text":
                # Criar clip de texto
                text_clip = create_text_clip(
                    element.content,
                    element.duration,
                    resolution,
                    element.style
                )

                # Adicionar Ã¡udio se disponÃ­vel
                if element.content in audio_files:
                    audio_clip = create_audio_clip(audio_files[element.content])
                    if audio_clip:
                        text_clip = text_clip.set_audio(audio_clip)
                        audio_clips.append(audio_clip)

                # Adicionar avatar se disponÃ­vel
                if element.content in avatar_files:
                    avatar_clip = VideoFileClip(avatar_files[element.content])
                    # Redimensionar avatar para tamanho do elemento
                    avatar_clip = avatar_clip.resize(element.size)
                    # Posicionar avatar
                    avatar_clip = avatar_clip.set_position((
                        element.position["x"] * resolution[0],
                        element.position["y"] * resolution[1]
                    ))
                    clips.append(avatar_clip)

                clips.append(text_clip)

            elif element.type == "image":
                # Criar clip de imagem
                img_clip = create_image_clip(
                    element.content,
                    element.duration,
                    resolution
                )
                clips.append(img_clip)

            elif element.type == "audio":
                # Criar clip de Ã¡udio
                audio_clip = create_audio_clip(element.content)
                if audio_clip:
                    # Criar clip visual para Ã¡udio
                    audio_visual = ColorClip(resolution, color=(50, 50, 50)).set_duration(audio_clip.duration)
                    audio_visual = audio_visual.set_audio(audio_clip)
                    clips.append(audio_visual)
                    audio_clips.append(audio_clip)

        # Combinar todos os clips da cena
        if clips:
            # Se hÃ¡ mÃºltiplos clips, combinar
            if len(clips) > 1:
                scene_clip = CompositeVideoClip(clips, size=resolution)
            else:
                scene_clip = clips[0]

            # Combinar Ã¡udios se houver mÃºltiplos
            if len(audio_clips) > 1:
                combined_audio = CompositeAudioClip(audio_clips)
                scene_clip = scene_clip.set_audio(combined_audio)

            return scene_clip
        else:
            # Fallback: clip vazio
            return ColorClip(resolution, color=(0, 0, 0)).set_duration(scene.duration)

    except Exception as e:
        logger.error(f"Erro ao criar clip da cena: {e}")
        # Fallback: clip simples
        return ColorClip(resolution, color=(100, 100, 100)).set_duration(scene.duration)

def send_export_notification(email: str, project_name: str, video_url: str):
    msg = MIMEText(f"Seu vÃ­deo do projeto '{project_name}' estÃ¡ pronto! Baixe em: {video_url}")
    msg['Subject'] = f"ExportaÃ§Ã£o IA concluÃ­da - {project_name}"
    msg['From'] = 'no-reply@tecnocursos.ai'
    msg['To'] = email
    try:
        with smtplib.SMTP('localhost') as server:
            server.send_message(msg)
    except Exception as e:
        print(f"Falha ao enviar e-mail: {e}")

# ===============================================================
# ENDPOINTS PRINCIPAIS
# ===============================================================

@router.post("/export", response_model=VideoExportResponse)
async def export_video(
    request: VideoExportRequest,
    background_tasks: BackgroundTasks,
    current_user: User = Depends(get_current_user) if AUTH_AVAILABLE else None
):
    """
    Exporta vÃ­deo final com todas as cenas e configuraÃ§Ãµes.

    Processo completo:
    1. Gera Ã¡udio TTS para textos com narraÃ§Ã£o IA
    2. Gera vÃ­deos de avatar (se habilitado)
    3. Monta cada cena com MoviePy
    4. Une todas as cenas com transiÃ§Ãµes
    5. Salva vÃ­deo final em MP4
    """
    try:
        if not VIDEO_FUNCTIONS_AVAILABLE or not MOVIEPY_AVAILABLE:
            raise HTTPException(
                status_code=503,
                detail="ServiÃ§o de exportaÃ§Ã£o de vÃ­deo temporariamente indisponÃ­vel"
            )

        # Gerar ID Ãºnico para o vÃ­deo
        video_id = f"export_{uuid.uuid4().hex[:12]}"

        # Validar resoluÃ§Ã£o
        if request.resolution not in RESOLUTION_CONFIGS:
            raise HTTPException(
                status_code=400,
                detail=f"ResoluÃ§Ã£o invÃ¡lida. VÃ¡lidas: {list(RESOLUTION_CONFIGS.keys())}"
            )

        # Validar qualidade
        if request.quality not in QUALITY_CONFIGS:
            raise HTTPException(
                status_code=400,
                detail=f"Qualidade invÃ¡lida. VÃ¡lidas: {list(QUALITY_CONFIGS.keys())}"
            )

        # Configurar TTS
        tts_config = TTSConfig(
            provider=TTSProvider(request.tts_provider),
            voice=request.tts_voice,
            language="pt",
            output_format="mp3"
        )

        # ApÃ³s iniciar exportaÃ§Ã£o, registrar vÃ­deo no banco
        from app.models import Video
        from app.database import get_db
        db = get_db()
        video = Video(
            title=request.title,
            filename=f"{video_id}.mp4",
            file_path=f"app/static/videos/{video_id}.mp4",
            file_size=0,  # Atualizar apÃ³s renderizaÃ§Ã£o
            duration=None,
            format="mp4",
            status="queued",
            project_id=getattr(request, 'project_id', None),
            source_file_id=None
        )
        db.add(video)
        db.commit()
        db.refresh(video)

        # Processar vÃ­deo em background
        background_tasks.add_task(
            process_video_export,
            video_id,
            request,
            tts_config,
            current_user.id if current_user else None
        )

        return VideoExportResponse(
            success=True,
            video_id=video_id,
            message="ExportaÃ§Ã£o de vÃ­deo iniciada. Use o ID para verificar o status.",
            data={
                "estimated_completion": "5-15 minutos",
                "status_endpoint": f"/api/video-export/{video_id}/status",
                "download_endpoint": f"/api/video-export/{video_id}/download",
                "scenes_count": len(request.scenes),
                "resolution": request.resolution,
                "quality": request.quality
            }
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro interno: {str(e)}")

@router.post("/export-ia", response_model=VideoExportResponse)
async def export_video_ia(
    project_id: int,
    tts_model: str = "coqui",
    avatar_model: str = "hunyuan3d2",
    current_user: User = Depends(get_current_user) if AUTH_AVAILABLE else None,
    db: Session = Depends(get_db)
):
    """
    Exporta vÃ­deo final do projeto com pipeline IA (TTS, avatar, assets, MoviePy).
    """
    project = db.query(Project).filter(Project.id == project_id).first()
    if not project:
        raise HTTPException(status_code=404, detail="Projeto nÃ£o encontrado")
    scenes = db.query(Scene).filter(Scene.project_id == project_id).order_by(Scene.ordem).all()
    assets = db.query(Asset).filter(Asset.project_id == project_id).all()
    final_video_path = export_project_video_with_ia(project, scenes, assets, tts_model, avatar_model)
    # Salvar/atualizar vÃ­deo no banco
    from app.models import Video
    video = Video(
        title=f"ExportaÃ§Ã£o IA {project.name}",
        filename=os.path.basename(final_video_path),
        file_path=final_video_path,
        file_size=os.path.getsize(final_video_path),
        duration=None,
        format="mp4",
        status="completed",
        project_id=project.id,
        source_file_id=None
    )
    db.add(video)
    db.commit()
    db.refresh(video)
    return VideoExportResponse(
        success=True,
        video_id=video.id,
        message="ExportaÃ§Ã£o IA concluÃ­da com sucesso.",
        data={
            "download_url": f"/static/videos/generated/project_{project.id}/final_project_video.mp4",
            "project_id": project.id,
            "video_id": video.id
        }
    )

@router.post("/export-ia-async", response_model=VideoExportResponse)
async def export_video_ia_async(
    project_id: int,
    tts_model: str = "coqui",
    avatar_model: str = "hunyuan3d2",
    background_tasks: BackgroundTasks = Depends(),
    current_user: User = Depends(get_current_user) if AUTH_AVAILABLE else None,
    db: Session = Depends(get_db)
):
    """
    Exporta vÃ­deo final do projeto com pipeline IA de forma assÃ­ncrona/background.
    """
    project = db.query(Project).filter(Project.id == project_id).first()
    if not project:
        raise HTTPException(status_code=404, detail="Projeto nÃ£o encontrado")
    scenes = db.query(Scene).filter(Scene.project_id == project_id).order_by(Scene.ordem).all()
    assets = db.query(Asset).filter(Asset.project_id == project_id).all()
    def on_finish(final_video_path):
        from app.models import Video
        video = Video(
            title=f"ExportaÃ§Ã£o IA {project.name}",
            filename=os.path.basename(final_video_path),
            file_path=final_video_path,
            file_size=os.path.getsize(final_video_path),
            duration=None,
            format="mp4",
            status="completed",
            project_id=project.id,
            source_file_id=None
        )
        db.add(video)
        db.commit()
        db.refresh(video)
        # Notificar usuÃ¡rio por e-mail se disponÃ­vel
        if hasattr(project, 'owner') and getattr(project.owner, 'email', None):
            send_export_notification(project.owner.email, project.name, final_video_path)
    from app.services.video_pipeline_service import export_project_video_with_ia_async
    background_tasks.add_task(export_project_video_with_ia_async(project, scenes, assets, tts_model, avatar_model, on_finish))
    return VideoExportResponse(
        success=True,
        video_id=None,
        message="ExportaÃ§Ã£o IA agendada em background. VocÃª serÃ¡ notificado ao finalizar.",
        data={
            "project_id": project.id
        }
    )

@router.get("/export-ia-status/{project_id}")
async def get_export_ia_status(project_id: int, db: Session = Depends(get_db)):
    """
    Consulta o status da Ãºltima exportaÃ§Ã£o IA do projeto.
    """
    from app.models import Video
    video = db.query(Video).filter(Video.project_id == project_id).order_by(Video.id.desc()).first()
    if not video:
        return JSONResponse(status_code=404, content={"status": "not_found", "message": "Nenhuma exportaÃ§Ã£o encontrada."})
    status = video.status or "unknown"
    data = {"status": status}
    if status == "completed":
        data["download_url"] = video.file_path
    return data

@router.get("/{video_id}/status", response_model=VideoStatusResponse)
async def get_video_export_status(
    video_id: str,
    current_user: User = Depends(get_current_user) if AUTH_AVAILABLE else None
):
    """Verifica o status de exportaÃ§Ã£o de um vÃ­deo"""
    try:
        # Verificar se job existe
        if video_id not in video_jobs:
            raise HTTPException(
                status_code=404,
                detail="VÃ­deo nÃ£o encontrado"
            )

        job = video_jobs[video_id]

        # Verificar se vÃ­deo estÃ¡ pronto
        video_path = f"app/static/videos/{video_id}.mp4"
        if os.path.exists(video_path):
            file_size = os.path.getsize(video_path)
            return VideoStatusResponse(
                video_id=video_id,
                status="completed",
                progress=100.0,
                current_stage="finished",
                video_url=f"/api/video-export/{video_id}/download",
                file_size=file_size,
                duration=job.get("duration", 0)
            )

        # Retornar status atual
        return VideoStatusResponse(
            video_id=video_id,
            status=job.get("status", "unknown"),
            progress=job.get("progress", 0),
            current_stage=job.get("current_stage", "unknown"),
            estimated_time=job.get("estimated_time"),
            error_message=job.get("error_message")
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro ao verificar status: {str(e)}")

@router.get("/{video_id}/download")
async def download_exported_video(
    video_id: str,
    current_user: User = Depends(get_current_user) if AUTH_AVAILABLE else None
):
    """Download do vÃ­deo exportado"""
    try:
        video_path = f"app/static/videos/{video_id}.mp4"

        if not os.path.exists(video_path):
            raise HTTPException(
                status_code=404,
                detail="VÃ­deo nÃ£o encontrado ou ainda nÃ£o processado"
            )

        return FileResponse(
            path=video_path,
            media_type="video/mp4",
            filename=f"{video_id}.mp4",
            headers={"Content-Disposition": f"attachment; filename={video_id}.mp4"}
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro no download: {str(e)}")

# ===============================================================
# FUNÃ‡ÃƒO DE PROCESSAMENTO EM BACKGROUND
# ===============================================================

async def process_video_export(
    video_id: str,
    request: VideoExportRequest,
    tts_config: TTSConfig,
    user_id: Optional[int] = None
):
    """Processa exportaÃ§Ã£o de vÃ­deo em background"""

    # Registrar job
    video_jobs[video_id] = {
        "status": "processing",
        "progress": 0,
        "current_stage": "Iniciando processamento",
        "start_time": time.time()
    }

    try:
        logger.info(f"ğŸ¬ Iniciando exportaÃ§Ã£o de vÃ­deo {video_id}")

        # Configurar resoluÃ§Ã£o
        resolution = RESOLUTION_CONFIGS[request.resolution]
        quality_config = QUALITY_CONFIGS[request.quality]

        # Atualizar progresso
        video_jobs[video_id]["progress"] = 5
        video_jobs[video_id]["current_stage"] = "Configurando projeto"

        # ========================================================================
        # ETAPA 1: GERAR ÃUDIOS TTS PARA TODAS AS CENAS
        # ========================================================================
        logger.info("ğŸ¤ ETAPA 1: Gerando Ã¡udios TTS...")
        video_jobs[video_id]["current_stage"] = "Gerando narraÃ§Ãµes TTS"
        video_jobs[video_id]["progress"] = 10

        all_audio_files = {}
        for i, scene in enumerate(request.scenes):
            # Gerar TTS para esta cena
            scene_audio_files = await generate_tts_for_scene(scene, tts_config)
            all_audio_files[scene.id] = scene_audio_files

            # Atualizar progresso
            progress = 10 + (i + 1) * 20 // len(request.scenes)
            video_jobs[video_id]["progress"] = progress

        # ========================================================================
        # ETAPA 2: GERAR VÃDEOS DE AVATAR (SE HABILITADO)
        # ========================================================================
        logger.info("ğŸ­ ETAPA 2: Gerando avatares...")
        video_jobs[video_id]["current_stage"] = "Gerando avatares"
        video_jobs[video_id]["progress"] = 30

        all_avatar_files = {}
        avatar_scenes = [s for s in request.scenes if s.avatar_enabled]

        for i, scene in enumerate(avatar_scenes):
            # Gerar avatares para esta cena
            scene_avatar_files = await generate_avatar_for_scene(
                scene,
                all_audio_files.get(scene.id, {})
            )
            all_avatar_files[scene.id] = scene_avatar_files

            # Atualizar progresso
            if avatar_scenes:
                progress = 30 + (i + 1) * 20 // len(avatar_scenes)
                video_jobs[video_id]["progress"] = progress

        # ========================================================================
        # ETAPA 3: MONTAR CLIPS DE CADA CENA
        # ========================================================================
        logger.info("ğŸ¬ ETAPA 3: Montando cenas...")
        video_jobs[video_id]["current_stage"] = "Montando cenas"
        video_jobs[video_id]["progress"] = 50

        scene_clips = []
        for i, scene in enumerate(request.scenes):
            # Criar clip da cena
            scene_clip = create_scene_clip(
                scene,
                all_audio_files.get(scene.id, {}),
                all_avatar_files.get(scene.id, {}),
                resolution,
                request.fps
            )
            scene_clips.append(scene_clip)

            # Atualizar progresso
            progress = 50 + (i + 1) * 30 // len(request.scenes)
            video_jobs[video_id]["progress"] = progress

        # ========================================================================
        # ETAPA 4: UNIR CENAS COM TRANSIÃ‡Ã•ES
        # ========================================================================
        logger.info("ğŸ”— ETAPA 4: Unindo cenas...")
        video_jobs[video_id]["current_stage"] = "Unindo cenas"
        video_jobs[video_id]["progress"] = 80

        final_clips = []
        for i, clip in enumerate(scene_clips):
            # Adicionar transiÃ§Ã£o se nÃ£o for o primeiro clip
            if i > 0 and i < len(request.scenes):
                prev_scene = request.scenes[i-1]
                transition_type = prev_scene.transition or "fade"
                clip, scene_clips[i] = add_transition(
                    scene_clips[i-1], clip, transition_type
                )

            final_clips.append(clip)

        # Concatenar todos os clips
        final_video = concatenate_videoclips(final_clips)

        # ========================================================================
        # ETAPA 5: ADICIONAR MÃšSICA DE FUNDO (SE ESPECIFICADA)
        # ========================================================================
        if request.background_music and os.path.exists(request.background_music):
            logger.info("ğŸµ ETAPA 5: Adicionando mÃºsica de fundo...")
            video_jobs[video_id]["current_stage"] = "Adicionando mÃºsica"

            try:
                background_audio = AudioFileClip(request.background_music)

                # Loop mÃºsica se necessÃ¡rio
                if background_audio.duration < final_video.duration:
                    loops_needed = int(final_video.duration / background_audio.duration) + 1
                    background_audio = concatenate_videoclips([background_audio] * loops_needed)

                # Cortar para duraÃ§Ã£o exata
                background_audio = background_audio.subclip(0, final_video.duration)

                # Reduzir volume da mÃºsica
                background_audio = background_audio.volumex(0.3)

                # Combinar com Ã¡udio do vÃ­deo
                if final_video.audio:
                    final_audio = CompositeAudioClip([final_video.audio, background_audio])
                    final_video = final_video.set_audio(final_audio)
                else:
                    final_video = final_video.set_audio(background_audio)

            except Exception as e:
                logger.error(f"Erro ao adicionar mÃºsica de fundo: {e}")

        # ========================================================================
        # ETAPA 6: SALVAR VÃDEO FINAL
        # ========================================================================
        logger.info("ğŸ’¾ ETAPA 6: Salvando vÃ­deo final...")
        video_jobs[video_id]["current_stage"] = "Salvando vÃ­deo"
        video_jobs[video_id]["progress"] = 90

        # Configurar caminho de saÃ­da
        output_path = f"app/static/videos/{video_id}.mp4"
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        # ConfiguraÃ§Ãµes de qualidade
        codec = "libx264"
        audio_codec = "aac"
        bitrate = quality_config["bitrate"]
        crf = quality_config["crf"]

        # Salvar vÃ­deo
        final_video.write_videofile(
            output_path,
            codec=codec,
            audio_codec=audio_codec,
            bitrate=bitrate,
            fps=request.fps,
            preset="medium",
            threads=4,
            verbose=False,
            logger=None
        )

        # Obter informaÃ§Ãµes do vÃ­deo
        file_size = os.path.getsize(output_path)
        duration = final_video.duration

        # Atualizar job com sucesso
        video_jobs[video_id].update({
            "status": "completed",
            "progress": 100,
            "current_stage": "ConcluÃ­do",
            "duration": duration,
            "file_size": file_size,
            "completed_at": datetime.now().isoformat()
        })

        logger.info(f"âœ… ExportaÃ§Ã£o de vÃ­deo {video_id} concluÃ­da!")
        logger.info(f"ğŸ“ Arquivo: {output_path}")
        logger.info(f"â±ï¸ DuraÃ§Ã£o: {duration:.2f}s")
        logger.info(f"ğŸ’¾ Tamanho: {file_size/1024/1024:.2f}MB")

        # Limpar recursos
        final_video.close()
        for clip in scene_clips:
            clip.close()

        # ApÃ³s exportar vÃ­deo, registrar no banco
        from app.models import Video
        db = get_db()
        video = Video(
            title=f"ExportaÃ§Ã£o {video_id}",
            filename=f"{video_id}.mp4",
            file_path=output_path,
            file_size=os.path.getsize(output_path) if os.path.exists(output_path) else 0,
            duration=request.duration if hasattr(request, 'duration') else None,
            format="mp4",
            status="completed",
            project_id=request.project_id if hasattr(request, 'project_id') else None,
            source_file_id=None
        )
        db.add(video)
        db.commit()
        db.refresh(video)

    except Exception as e:
        error_msg = f"Erro na exportaÃ§Ã£o: {str(e)}"
        logger.error(f"âŒ {error_msg}")

        # Atualizar job com erro
        video_jobs[video_id].update({
            "status": "failed",
            "progress": 0,
            "current_stage": "Erro",
            "error_message": error_msg
        })

# ===============================================================
# ENDPOINTS DE INFORMAÃ‡ÃƒO E STATUS
# ===============================================================

@router.get("/info")
async def get_video_export_info():
    """InformaÃ§Ãµes sobre o serviÃ§o de exportaÃ§Ã£o de vÃ­deo"""
    return {
        "service": "TecnoCursos AI - Video Export API",
        "version": "1.0.0",
        "status": "operational" if VIDEO_FUNCTIONS_AVAILABLE and MOVIEPY_AVAILABLE else "limited",
        "capabilities": {
            "tts_generation": TTSProvider is not None,
            "avatar_generation": True,
            "video_montage": MOVIEPY_AVAILABLE,
            "transitions": True,
            "background_music": True,
            "multiple_resolutions": True
        },
        "supported_formats": {
            "input_audio": ["MP3", "WAV"],
            "output_video": ["MP4"],
            "resolutions": list(RESOLUTION_CONFIGS.keys()),
            "qualities": list(QUALITY_CONFIGS.keys())
        },
        "tts_providers": ["auto", "bark", "gtts"] if TTSProvider else [],
        "avatar_styles": ["professional", "educational", "tech", "minimal"],
        "transitions": ["fade", "slide", "zoom"],
        "limits": {
            "max_scenes": 50,
            "max_scene_duration": 300,  # 5 minutos
            "max_total_duration": 3600,  # 1 hora
            "max_file_size": "500MB"
        },
        "endpoints": {
            "export": "/api/video-export/export",
            "status": "/api/video-export/{id}/status",
            "download": "/api/video-export/{id}/download",
            "info": "/api/video-export/info"
        }
    }

# Exportar router
video_export_router = router
