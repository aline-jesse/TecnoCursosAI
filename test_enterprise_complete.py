#!/usr/bin/env python3
"""
Teste Completo do Sistema Enterprise TecnoCursos AI
==================================================

Script de valida√ß√£o completa de todas as implementa√ß√µes enterprise:
- AI Guardrails Service
- Compliance Service  
- Security Hardening Service
- Intelligent Monitoring Service
- API Versioning Service
- Load Balancing Service
- Auto Documentation Service

Autor: TecnoCursos AI Team
Data: 2024-12-17
"""

import asyncio
import sys
import logging
from pathlib import Path
from datetime import datetime

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_imports():
    """Testa se todos os servi√ßos podem ser importados"""
    
    print("üîç TESTANDO IMPORTA√á√ïES DOS SERVI√áOS ENTERPRISE...")
    
    services_status = {}
    
    # AI Guardrails Service
    try:
        from app.services.ai_guardrails_service import ai_guardrails_service, DecisionCategory
        services_status["ai_guardrails"] = "‚úÖ OK"
        print("   ‚úÖ AI Guardrails Service - IMPORTADO")
    except ImportError as e:
        services_status["ai_guardrails"] = f"‚ùå ERRO: {e}"
        print(f"   ‚ùå AI Guardrails Service - ERRO: {e}")
    
    # Compliance Service
    try:
        from app.services.ai_compliance_service import ai_compliance_service, ComplianceStandard
        services_status["compliance"] = "‚úÖ OK"
        print("   ‚úÖ Compliance Service - IMPORTADO")
    except ImportError as e:
        services_status["compliance"] = f"‚ùå ERRO: {e}"
        print(f"   ‚ùå Compliance Service - ERRO: {e}")
    
    # Security Service
    try:
        from app.services.security_hardening_service import security_hardening_service, ThreatLevel
        services_status["security"] = "‚úÖ OK"
        print("   ‚úÖ Security Hardening Service - IMPORTADO")
    except ImportError as e:
        services_status["security"] = f"‚ùå ERRO: {e}"
        print(f"   ‚ùå Security Hardening Service - ERRO: {e}")
    
    # Monitoring Service
    try:
        from app.services.intelligent_monitoring_service import intelligent_monitoring_service, MetricType
        services_status["monitoring"] = "‚úÖ OK"
        print("   ‚úÖ Intelligent Monitoring Service - IMPORTADO")
    except ImportError as e:
        services_status["monitoring"] = f"‚ùå ERRO: {e}"
        print(f"   ‚ùå Intelligent Monitoring Service - ERRO: {e}")
    
    # Versioning Service
    try:
        from app.services.api_versioning_service import api_versioning_service, VersionStatus
        services_status["versioning"] = "‚úÖ OK"
        print("   ‚úÖ API Versioning Service - IMPORTADO")
    except ImportError as e:
        services_status["versioning"] = f"‚ùå ERRO: {e}"
        print(f"   ‚ùå API Versioning Service - ERRO: {e}")
    
    # Load Balancing Service
    try:
        from app.services.load_balancing_service import load_balancing_service, LoadBalancingAlgorithm
        services_status["load_balancing"] = "‚úÖ OK"
        print("   ‚úÖ Load Balancing Service - IMPORTADO")
    except ImportError as e:
        services_status["load_balancing"] = f"‚ùå ERRO: {e}"
        print(f"   ‚ùå Load Balancing Service - ERRO: {e}")
    
    # Documentation Service
    try:
        from app.services.auto_documentation_service import auto_documentation_service, CodeLanguage
        services_status["documentation"] = "‚úÖ OK"
        print("   ‚úÖ Auto Documentation Service - IMPORTADO")
    except ImportError as e:
        services_status["documentation"] = f"‚ùå ERRO: {e}"
        print(f"   ‚ùå Auto Documentation Service - ERRO: {e}")
    
    # Enterprise Router
    try:
        from app.routers.enterprise_router import enterprise_router
        services_status["enterprise_router"] = "‚úÖ OK"
        print("   ‚úÖ Enterprise Router - IMPORTADO")
    except ImportError as e:
        services_status["enterprise_router"] = f"‚ùå ERRO: {e}"
        print(f"   ‚ùå Enterprise Router - ERRO: {e}")
    
    return services_status

async def test_ai_guardrails():
    """Testa o AI Guardrails Service"""
    
    print("\nüõ°Ô∏è TESTANDO AI GUARDRAILS SERVICE...")
    
    try:
        from app.services.ai_guardrails_service import ai_guardrails_service, DecisionCategory
        
        # Teste de avalia√ß√£o de decis√£o
        decision = await ai_guardrails_service.evaluate_decision(
            action="test_action",
            category=DecisionCategory.CONTENT_GENERATION,
            context={"test": True},
            confidence=0.8
        )
        
        print(f"   ‚úÖ Decis√£o avaliada: {decision.id}")
        print(f"   ‚úÖ N√≠vel de risco: {decision.risk_level.value}")
        print(f"   ‚úÖ Explica√ß√£o: {decision.explanation[:50]}...")
        
        # Teste de m√©tricas
        metrics = ai_guardrails_service.get_metrics()
        print(f"   ‚úÖ M√©tricas obtidas: {len(metrics)} itens")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå ERRO no AI Guardrails: {e}")
        return False

async def test_compliance():
    """Testa o Compliance Service"""
    
    print("\nüìã TESTANDO COMPLIANCE SERVICE...")
    
    try:
        from app.services.ai_compliance_service import ai_compliance_service, ComplianceStandard
        
        # Teste de detec√ß√£o de bias
        detections = await ai_compliance_service.detect_bias(
            "Este √© um texto de teste para detectar poss√≠vel bias de g√™nero."
        )
        
        print(f"   ‚úÖ Detec√ß√µes de bias: {len(detections)}")
        
        # Teste de check de compliance
        check = await ai_compliance_service.check_compliance(
            ComplianceStandard.GDPR,
            {"user_consent": True, "contains_personal_data": False}
        )
        
        print(f"   ‚úÖ Check GDPR: {check.status}")
        print(f"   ‚úÖ Findings: {len(check.findings)}")
        
        # Teste de m√©tricas
        metrics = ai_compliance_service.get_compliance_metrics()
        print(f"   ‚úÖ M√©tricas de compliance: {len(metrics)} itens")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå ERRO no Compliance: {e}")
        return False

async def test_security():
    """Testa o Security Hardening Service"""
    
    print("\nüîí TESTANDO SECURITY HARDENING SERVICE...")
    
    try:
        from app.services.security_hardening_service import security_hardening_service
        
        # Teste de an√°lise de request
        request_data = {
            "client_ip": "192.168.1.100",
            "user_agent": "TestAgent/1.0",
            "method": "GET",
            "url": "/test",
            "headers": {"Content-Type": "application/json"},
            "body": ""
        }
        
        allowed, incidents = await security_hardening_service.analyze_request_security(request_data)
        
        print(f"   ‚úÖ Request analisado - Permitido: {allowed}")
        print(f"   ‚úÖ Incidentes detectados: {len(incidents)}")
        
        # Teste de criptografia
        test_data = "Dados sens√≠veis para criptografar"
        encrypted = security_hardening_service.encrypt_data(test_data)
        decrypted = security_hardening_service.decrypt_data(encrypted)
        
        print(f"   ‚úÖ Criptografia funcionando: {decrypted == test_data}")
        
        # Teste de m√©tricas
        metrics = security_hardening_service.get_security_metrics()
        print(f"   ‚úÖ M√©tricas de seguran√ßa: {len(metrics)} itens")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå ERRO no Security: {e}")
        return False

async def test_monitoring():
    """Testa o Intelligent Monitoring Service"""
    
    print("\nüìà TESTANDO INTELLIGENT MONITORING SERVICE...")
    
    try:
        from app.services.intelligent_monitoring_service import intelligent_monitoring_service, MetricType
        
        # Teste de adi√ß√£o de m√©trica customizada
        await intelligent_monitoring_service.add_custom_metric(
            MetricType.CPU_USAGE,
            75.5,
            {"source": "test"},
            "test_application"
        )
        
        print("   ‚úÖ M√©trica customizada adicionada")
        
        # Teste de sa√∫de do sistema
        health = intelligent_monitoring_service.get_system_health()
        print(f"   ‚úÖ Status de sa√∫de: {health.value}")
        
        # Teste de m√©tricas
        stats = intelligent_monitoring_service.get_monitoring_stats()
        print(f"   ‚úÖ Stats de monitoramento: {len(stats)} itens")
        
        # Teste de dashboard
        dashboard = intelligent_monitoring_service.generate_dashboard_data()
        print(f"   ‚úÖ Dashboard gerado com timestamp: {dashboard['timestamp']}")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå ERRO no Monitoring: {e}")
        return False

async def test_versioning():
    """Testa o API Versioning Service"""
    
    print("\nüîÑ TESTANDO API VERSIONING SERVICE...")
    
    try:
        from app.services.api_versioning_service import api_versioning_service
        
        # Teste de negocia√ß√£o de vers√£o
        headers = {"API-Version": "1.0.0"}
        query_params = {}
        
        version = await api_versioning_service.negotiate_version(headers, query_params)
        print(f"   ‚úÖ Vers√£o negociada: {version}")
        
        # Teste de informa√ß√µes de vers√£o
        version_info = api_versioning_service.get_version_info("1.0.0")
        print(f"   ‚úÖ Info da vers√£o obtida: {version_info['version'] if version_info else 'N/A'}")
        
        # Teste de stats
        stats = api_versioning_service.get_versioning_stats()
        print(f"   ‚úÖ Stats de versionamento: {stats['total_versions']} vers√µes")
        
        # Teste de compatibilidade
        compat = await api_versioning_service.get_compatibility_info("1.0.0", "2.0.0")
        print(f"   ‚úÖ Compatibilidade 1.0.0 -> 2.0.0: {compat['compatibility_level']}")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå ERRO no Versioning: {e}")
        return False

async def test_load_balancing():
    """Testa o Load Balancing Service"""
    
    print("\n‚öñÔ∏è TESTANDO LOAD BALANCING SERVICE...")
    
    try:
        from app.services.load_balancing_service import load_balancing_service, LoadBalancingAlgorithm
        
        # Registrar servidor de teste
        server = await load_balancing_service.register_server(
            "test_server_1",
            "localhost",
            8000,
            weight=1,
            group="test"
        )
        
        print(f"   ‚úÖ Servidor registrado: {server.id}")
        
        # Teste de sele√ß√£o de servidor
        selected = await load_balancing_service.select_server(
            client_ip="192.168.1.100",
            group="test"
        )
        
        if selected:
            print(f"   ‚úÖ Servidor selecionado: {selected.id}")
        else:
            print("   ‚ö†Ô∏è Nenhum servidor dispon√≠vel")
        
        # Teste de m√©tricas
        metrics = load_balancing_service.get_load_balancing_metrics()
        print(f"   ‚úÖ M√©tricas de load balancing: {metrics['total_servers']} servidores")
        
        # Teste de algorithm change
        load_balancing_service.set_load_balancing_algorithm(LoadBalancingAlgorithm.ROUND_ROBIN)
        print("   ‚úÖ Algoritmo alterado para Round Robin")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå ERRO no Load Balancing: {e}")
        return False

async def test_documentation():
    """Testa o Auto Documentation Service"""
    
    print("\nüìö TESTANDO AUTO DOCUMENTATION SERVICE...")
    
    try:
        from app.services.auto_documentation_service import auto_documentation_service, CodeLanguage
        
        # Teste de gera√ß√£o OpenAPI
        openapi_spec = await auto_documentation_service.generate_openapi_spec("2.0.0")
        print(f"   ‚úÖ OpenAPI spec gerado - Vers√£o: {openapi_spec['info']['version']}")
        print(f"   ‚úÖ Paths documentados: {len(openapi_spec['paths'])}")
        
        # Teste de gera√ß√£o de SDK
        python_sdk = await auto_documentation_service.generate_sdk_code(CodeLanguage.PYTHON)
        print(f"   ‚úÖ SDK Python gerado: {len(python_sdk)} caracteres")
        
        # Teste de stats
        stats = auto_documentation_service.get_documentation_stats()
        print(f"   ‚úÖ Stats de documenta√ß√£o: {stats['total_endpoints']} endpoints")
        
        return True
        
    except Exception as e:
        print(f"   ‚ùå ERRO na Documentation: {e}")
        return False

def test_file_structure():
    """Testa se todos os arquivos foram criados"""
    
    print("\nüìÅ TESTANDO ESTRUTURA DE ARQUIVOS...")
    
    required_files = [
        "app/services/ai_guardrails_service.py",
        "app/services/ai_compliance_service.py", 
        "app/services/security_hardening_service.py",
        "app/services/intelligent_monitoring_service.py",
        "app/services/api_versioning_service.py",
        "app/services/load_balancing_service.py",
        "app/services/auto_documentation_service.py",
        "app/routers/enterprise_router.py",
        "SISTEMA_ENTERPRISE_FINALIZADO.md"
    ]
    
    missing_files = []
    existing_files = []
    
    for file_path in required_files:
        if Path(file_path).exists():
            size = Path(file_path).stat().st_size
            existing_files.append(f"{file_path} ({size:,} bytes)")
            print(f"   ‚úÖ {file_path} - {size:,} bytes")
        else:
            missing_files.append(file_path)
            print(f"   ‚ùå {file_path} - N√ÉO ENCONTRADO")
    
    return len(missing_files) == 0, existing_files, missing_files

async def main():
    """Fun√ß√£o principal de teste"""
    
    print("üè¢ TESTE COMPLETO DO SISTEMA ENTERPRISE TECNOCURSOS AI")
    print("=" * 60)
    print(f"Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # Resultados dos testes
    test_results = {}
    
    # 1. Teste de importa√ß√µes
    print("\n" + "="*60)
    services_status = test_imports()
    successful_imports = len([s for s in services_status.values() if "‚úÖ" in s])
    total_imports = len(services_status)
    test_results["imports"] = successful_imports == total_imports
    
    # 2. Teste de estrutura de arquivos
    print("\n" + "="*60)
    files_ok, existing_files, missing_files = test_file_structure()
    test_results["files"] = files_ok
    
    # 3. Testes funcionais (apenas se imports est√£o OK)
    if test_results["imports"]:
        print("\n" + "="*60)
        
        # Teste individual de cada servi√ßo
        test_results["ai_guardrails"] = await test_ai_guardrails()
        test_results["compliance"] = await test_compliance()
        test_results["security"] = await test_security()
        test_results["monitoring"] = await test_monitoring()
        test_results["versioning"] = await test_versioning()
        test_results["load_balancing"] = await test_load_balancing()
        test_results["documentation"] = await test_documentation()
    
    # Resumo final
    print("\n" + "="*60)
    print("üìä RESUMO DOS TESTES")
    print("="*60)
    
    passed_tests = len([r for r in test_results.values() if r])
    total_tests = len(test_results)
    success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
    
    for test_name, result in test_results.items():
        status = "‚úÖ PASSOU" if result else "‚ùå FALHOU"
        print(f"   {test_name.upper()}: {status}")
    
    print("\n" + "="*60)
    print(f"üéØ RESULTADO FINAL:")
    print(f"   Testes Passados: {passed_tests}/{total_tests}")
    print(f"   Taxa de Sucesso: {success_rate:.1f}%")
    
    if success_rate >= 90:
        print(f"   Status: ‚úÖ SISTEMA ENTERPRISE FUNCIONANDO")
        print(f"   Importa√ß√µes: {successful_imports}/{total_imports} servi√ßos")
        print(f"   Arquivos: {len(existing_files)} criados")
    elif success_rate >= 70:
        print(f"   Status: ‚ö†Ô∏è SISTEMA PARCIALMENTE FUNCIONANDO")
    else:
        print(f"   Status: ‚ùå SISTEMA COM PROBLEMAS")
    
    print("="*60)
    
    # Informa√ß√µes adicionais
    if test_results["files"]:
        print(f"\nüìÅ ARQUIVOS CRIADOS ({len(existing_files)}):")
        for file_info in existing_files:
            print(f"   üìÑ {file_info}")
    
    if missing_files:
        print(f"\n‚ùå ARQUIVOS FALTANDO ({len(missing_files)}):")
        for file_path in missing_files:
            print(f"   üìÑ {file_path}")
    
    print(f"\nüöÄ ENDPOINTS ENTERPRISE DISPON√çVEIS:")
    print(f"   üì° /enterprise/dashboard - Dashboard unificado")
    print(f"   üîç /enterprise/health - Health check completo")
    print(f"   üõ°Ô∏è /enterprise/guardrails/* - AI Guardrails")
    print(f"   üìã /enterprise/compliance/* - Compliance")
    print(f"   üîí /enterprise/security/* - Seguran√ßa")
    print(f"   üìà /enterprise/monitoring/* - Monitoramento")
    print(f"   üîÑ /enterprise/versioning/* - Versionamento")
    print(f"   ‚öñÔ∏è /enterprise/load-balancing/* - Load Balancing")
    print(f"   üìö /enterprise/documentation/* - Documenta√ß√£o")
    
    print(f"\nüìö DOCUMENTA√á√ÉO:")
    print(f"   üìñ SISTEMA_ENTERPRISE_FINALIZADO.md - Documenta√ß√£o completa")
    print(f"   üîó /docs - Swagger UI")
    print(f"   üìä /enterprise/documentation/openapi - OpenAPI Spec")
    
    return success_rate >= 90

if __name__ == "__main__":
    try:
        # Executar testes
        success = asyncio.run(main())
        
        if success:
            print("\nüéâ TODOS OS TESTES PASSARAM - SISTEMA ENTERPRISE OPERACIONAL!")
            sys.exit(0)
        else:
            print("\n‚ö†Ô∏è ALGUNS TESTES FALHARAM - VERIFICAR IMPLEMENTA√á√ÉO")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Teste interrompido pelo usu√°rio")
        sys.exit(1)
    except Exception as e:
        print(f"\n\n‚ùå ERRO CR√çTICO NO TESTE: {e}")
        sys.exit(1) 